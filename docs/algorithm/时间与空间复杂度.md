# 算法复杂度

数据结构和算法本质上是”快“和"省"。所以代码的执行效率是非常重要的度量，我们采用时间复杂度和空间复杂度来计算

常常使用**大O复杂度表示法**来表示

## 大O复杂表示法是什么？

大O符号（Big O notation）是用于描述函数渐进行为的数学符号。更确切地说，它是用另一个（通常更简单的）函数来描述一个函数数量级的渐近上界。在数学中，它一般用来刻画被截断的无穷级数尤其是渐近级数的剩余项；在计算机科学中，它在分析算法复杂性的方面非常有用。

| 符号                | 名称                                 |
| ------------------- | ------------------------------------ |
| O(1)                | 常数（阶，下同）                     |
| O(log*n)            | 迭代对数                             |
| O(log n)            | 对数                                 |
| O[(log n)^c]        | 多对数                               |
| O(n)                | 线性，次线性                         |
| O(n log n)          | 线性代数，或对数线性、拟线性、超线性 |
| O(n^2)              | 平方                                 |
| O(n^c),Integer(c>1) | 多项式，有时叫作“代数”（阶）         |
| O(c^n)              | 指数，有时叫作“几何”（阶）           |
| O(n!)               | 阶乘，有时叫做“组合”（阶）           |

## 时间复杂度

### O(1) 常量级

这种是最简单的，也是最好理解的，就是常量级不是只执行了一行代码，只要代码的执行不随着数据规模(n)的增加而增加，就是常量级

在实际应用中，通常使用冗余字段存储来将O(n)变成O(1)，比如Redis中有很多这样的操作用来提升访问性能

比如:SDS、字典、跳跃表等

### O(n)

```java
int sum(int n){
  int s=0; //t
  int i=1; //t
  for(;i<=n;i++){ //t*n
    s=s+i;  //t*n
  }
  return s; //t
}
```

> 上述是一段简单的循环代码，我们假设每行为一个执行单位t，n=100时，那么最终执行总单位为 n\*1+n\*1+100\*n+100\*n+n*1=200n+3n
>
> 当n无限大时，低阶、常量、系统都可以忽略，那么最终T(n)=O(n)

所以最终得出结论：

**我们假设执行一行代码的时间为t，通过估算，代码的执行时间T(n)与执行次数成正比，记做:**

```java
T(n)=O(f(n))
```

* T(n)：代码执行时间

* n：数据规模
* f(n)：每行代码执行次数总和
* O：代码的执行时间与f(n)表达式成正比

即上例中的时间复杂度为**O(n)**，也就是代码执行时间随着数据规模的增加而增长

比如:数组的插入删除、链表的遍历等



### O(logn)

```java
i = 1;
while(i <= n){
   i=i*2;  //执行最多 
}
```

根据复杂度分析方法，可以看出第三行的代码执行次数是最多的，所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度，代码中可以看到，i从1开始，每次循环乘2，大于n，循环结束，这不就是等比数列，如果把计算过程挨个描述一遍大概就是 2^0	2^1	2^2	2^3	2^4	2^5 ....	2^x = n

所以只要知道x的值就知道这段代码的执行次数了，2x=n 的求解，x=log2^n，所以这段代码的时间复杂度应该是O(log2^n)

那现在将这段代码稍微改一下，那时间复杂度是多少呢？

```java
i = 1;
while(i <= n){
   i=i*3;  //执行最多 
}
```

根据刚才的计算方式，很明确能得到结果 O(log3^n)

实际上不管是以2为底，以3为底数，还是以10为底数，我们可以把所有对数的时间复杂度都记为O(log n)，为什么呢，因为我们知道对数之间是可以转换的，O (log3^n ) 就等于O (log3^2) \* O (log2^n)，所以O (log3^2) = O(C*log2^n)，其中C = log3^2 是一个常量，根据之前的理论，在采用大O表示法的时候，可以忽略系数，即O(Cf()) = O(f(n))。所以最终的时间复杂度应该为O(log n)

### O(nlogn)

如果一段代码的时间复杂度是O(log n)，如果将该代码执行n遍，则时间复杂度记录为：T(n)=O(n*logn)，即O(nlogn) 

快速排序、归并排序的时间复杂度都是O(n log n)

### O(m+n)

代码的时间复杂度由两个数据的规模来决定

```java
int sum(int m,int n){
    int s1=0;
    int s2=0;
    int i=1;
    int j=1;
    for(;i<=m;i++){
			s1=s1+i; // 执行最多 
    }
    for(;j<=n;j++){ 
      s2=s2+j; //执行最多
    }
    return s1+s2;
}
```

m和n是代码的两个数据规模，而且不能确定谁更大，此时代码的复杂度为两段时间复杂度之和， 即

T(n)=O(m+n)，记作:O(m+n)

### **O(m\*n)**

```java
int sum(int n){
    int s=0;
    int i=1;
    int j=1;
    for(;i<=m;i++){// m
        j=1;
        for(;j<=n;j++){ //m*n
            s=s+i+j;    //m*n
        }
	}
	return s; 
}
```

根据乘法法则代码的复杂度为两段时间复杂度之积，即 T(n)=O(m\*n)，记作:O(m\*n)
 当m==n时,为O(n^2 )

## 空间复杂度

空间复杂度全称是渐进空间复杂度，表示算法的存储空间与数据规模之间的增长关系

比如将一个数组拷贝到另一个数组中就是相当于空间扩大了一倍:T(n)=O(2n)，忽略系数。

即为:O(n)，这是一个非常常见的空间复杂度，比如跳跃表、hashmap的扩容 

此外还有:O(1)，比如原地排序、O(n^2)此种占用空间过大

由于现在硬件相对比较便宜，所以在开发中常常会利用空间来换时间，比如缓存技术

典型的数据结构中空间换时间是:跳跃表 

在实际开发中我们也更关注代码的时间复杂度，而用于执行效率的提升
